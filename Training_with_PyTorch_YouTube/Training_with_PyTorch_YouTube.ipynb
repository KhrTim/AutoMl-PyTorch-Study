{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag  Coat  Sandal  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8885, 0.8198, 0.8307, 0.9797, 0.2799, 0.4620, 0.4235, 0.7361, 0.4773,\n",
      "         0.0590],\n",
      "        [0.0031, 0.1070, 0.3720, 0.3268, 0.2989, 0.5861, 0.0244, 0.1891, 0.7926,\n",
      "         0.5622],\n",
      "        [0.8094, 0.7529, 0.4316, 0.6295, 0.5829, 0.1030, 0.5276, 0.4930, 0.1962,\n",
      "         0.0623],\n",
      "        [0.6336, 0.2887, 0.1851, 0.1872, 0.1252, 0.7739, 0.3689, 0.5582, 0.0391,\n",
      "         0.6128]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.1257476806640625\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Epoch Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.7710528967380523\n",
      "  batch 2000 loss: 0.873670666065067\n",
      "  batch 3000 loss: 0.7268360738903284\n",
      "  batch 4000 loss: 0.6421127838008106\n",
      "  batch 5000 loss: 0.5964561086161994\n",
      "  batch 6000 loss: 0.5623552287216298\n",
      "  batch 7000 loss: 0.5236066110022366\n",
      "  batch 8000 loss: 0.5065127635307144\n",
      "  batch 9000 loss: 0.49209372744103896\n",
      "  batch 10000 loss: 0.4606874833747861\n",
      "  batch 11000 loss: 0.4369341992549598\n",
      "  batch 12000 loss: 0.44670802551860106\n",
      "  batch 13000 loss: 0.4455015685707331\n",
      "  batch 14000 loss: 0.42204121171950826\n",
      "  batch 15000 loss: 0.4152915605866583\n",
      "LOSS train 0.4152915605866583 valid 0.40790680050849915\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.3931242869542912\n",
      "  batch 2000 loss: 0.40177340707404074\n",
      "  batch 3000 loss: 0.4024773520339513\n",
      "  batch 4000 loss: 0.39474384937796275\n",
      "  batch 5000 loss: 0.387050149527\n",
      "  batch 6000 loss: 0.3729177632434585\n",
      "  batch 7000 loss: 0.3683614852337632\n",
      "  batch 8000 loss: 0.3611061686738976\n",
      "  batch 9000 loss: 0.3622260209873202\n",
      "  batch 10000 loss: 0.36065898780542194\n",
      "  batch 11000 loss: 0.34982422604996827\n",
      "  batch 12000 loss: 0.35962032372871183\n",
      "  batch 13000 loss: 0.3636846901309909\n",
      "  batch 14000 loss: 0.348167374624114\n",
      "  batch 15000 loss: 0.35132829343760386\n",
      "LOSS train 0.35132829343760386 valid 0.3953351080417633\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.3464220158268872\n",
      "  batch 2000 loss: 0.3390206527863338\n",
      "  batch 3000 loss: 0.33879371369135336\n",
      "  batch 4000 loss: 0.3284025660383049\n",
      "  batch 5000 loss: 0.3403638550487958\n",
      "  batch 6000 loss: 0.33504747199633855\n",
      "  batch 7000 loss: 0.3458140014242963\n",
      "  batch 8000 loss: 0.30798331917019095\n",
      "  batch 9000 loss: 0.3038539430366363\n",
      "  batch 10000 loss: 0.3134642537573018\n",
      "  batch 11000 loss: 0.331621532155099\n",
      "  batch 12000 loss: 0.3151821243351733\n",
      "  batch 13000 loss: 0.3187991344606926\n",
      "  batch 14000 loss: 0.32339202242650206\n",
      "  batch 15000 loss: 0.31060878188249624\n",
      "LOSS train 0.31060878188249624 valid 0.34256261587142944\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.3015505712681625\n",
      "  batch 2000 loss: 0.2817680613040211\n",
      "  batch 3000 loss: 0.3050066752037237\n",
      "  batch 4000 loss: 0.30636653170602224\n",
      "  batch 5000 loss: 0.29270501404374955\n",
      "  batch 6000 loss: 0.30629619445472417\n",
      "  batch 7000 loss: 0.29498863393049396\n",
      "  batch 8000 loss: 0.29323328139849764\n",
      "  batch 9000 loss: 0.3112715716431994\n",
      "  batch 10000 loss: 0.30424300552687783\n",
      "  batch 11000 loss: 0.28473274022927947\n",
      "  batch 12000 loss: 0.3060223387523511\n",
      "  batch 13000 loss: 0.3076067047788965\n",
      "  batch 14000 loss: 0.31204343810525553\n",
      "  batch 15000 loss: 0.2949043430936581\n",
      "LOSS train 0.2949043430936581 valid 0.30802568793296814\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.28122093267069614\n",
      "  batch 2000 loss: 0.27072335418715376\n",
      "  batch 3000 loss: 0.2708146979788289\n",
      "  batch 4000 loss: 0.30172386817474034\n",
      "  batch 5000 loss: 0.27410707678351903\n",
      "  batch 6000 loss: 0.29244016006207674\n",
      "  batch 7000 loss: 0.2867266099585686\n",
      "  batch 8000 loss: 0.3031449673203024\n",
      "  batch 9000 loss: 0.2713822104810224\n",
      "  batch 10000 loss: 0.29133502132499417\n",
      "  batch 11000 loss: 0.28363369029702423\n",
      "  batch 12000 loss: 0.2503072382794198\n",
      "  batch 13000 loss: 0.2698856304636938\n",
      "  batch 14000 loss: 0.28277199864429553\n",
      "  batch 15000 loss: 0.2861414217036217\n",
      "LOSS train 0.2861414217036217 valid 0.30529284477233887\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(\"model_20240330_222807_4\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
