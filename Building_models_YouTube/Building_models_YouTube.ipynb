{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0620,  0.0660,  0.0707,  ...,  0.0799,  0.0794,  0.0979],\n",
      "        [ 0.0418,  0.0394, -0.0640,  ..., -0.0179,  0.0752, -0.0393],\n",
      "        [-0.0414, -0.0441, -0.0683,  ..., -0.0686,  0.0184,  0.0591],\n",
      "        ...,\n",
      "        [-0.0908, -0.0789, -0.0451,  ...,  0.0581, -0.0132,  0.0454],\n",
      "        [ 0.0086, -0.0148,  0.0012,  ..., -0.0038,  0.0927, -0.0347],\n",
      "        [-0.0278,  0.0395,  0.0734,  ..., -0.0638,  0.0131,  0.0714]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0898, -0.0145,  0.0835, -0.0528, -0.0333,  0.0438,  0.0250, -0.0918,\n",
      "         0.0284, -0.0444, -0.0172,  0.0484,  0.0569, -0.0043, -0.0932,  0.0785,\n",
      "         0.0246,  0.0246,  0.0758,  0.0325,  0.0821,  0.0807,  0.0433, -0.0717,\n",
      "        -0.0319,  0.0949, -0.0167, -0.0935,  0.0122,  0.0211,  0.0867, -0.0071,\n",
      "        -0.0441,  0.0317,  0.0058, -0.0228,  0.0784, -0.0110, -0.0738,  0.0394,\n",
      "        -0.0517,  0.0404, -0.0607,  0.0327, -0.0836,  0.0092, -0.0134,  0.0560,\n",
      "         0.0481,  0.0107, -0.0806,  0.0642, -0.0153, -0.0097, -0.0099,  0.0042,\n",
      "         0.0341,  0.0025, -0.0826, -0.0074, -0.0075,  0.0414,  0.0991,  0.0952,\n",
      "        -0.0843,  0.0957, -0.0393, -0.0953,  0.0329,  0.0501, -0.0925,  0.0076,\n",
      "        -0.0710, -0.0092,  0.0472, -0.0665,  0.0118, -0.0763, -0.0714,  0.0551,\n",
      "         0.0112, -0.0531,  0.0706, -0.0040,  0.0345,  0.0367,  0.0072, -0.0454,\n",
      "         0.0759, -0.0788, -0.0471, -0.0734, -0.0747, -0.0135, -0.0440, -0.0122,\n",
      "         0.0301,  0.0176,  0.0513, -0.0085, -0.0041, -0.0073, -0.0431,  0.0794,\n",
      "        -0.0053,  0.0207,  0.0121, -0.0848,  0.0447,  0.0171,  0.0259,  0.0578,\n",
      "        -0.0511,  0.0682,  0.0375, -0.0811, -0.0687,  0.0104,  0.0191, -0.0089,\n",
      "         0.0687, -0.0090,  0.0776,  0.0955,  0.0433, -0.0125,  0.0146, -0.0244,\n",
      "        -0.0815, -0.0149, -0.0786, -0.0964, -0.0615,  0.0105, -0.0412, -0.0129,\n",
      "        -0.0846, -0.0692,  0.0092,  0.0022,  0.0795,  0.0958,  0.0540, -0.0931,\n",
      "        -0.0484,  0.0556, -0.0354,  0.0744, -0.0491,  0.0135,  0.0127,  0.0711,\n",
      "        -0.0303, -0.0331, -0.0355,  0.0183, -0.0570, -0.0915, -0.0003,  0.0547,\n",
      "         0.0347, -0.0548,  0.0974,  0.0880,  0.0621, -0.0926,  0.0324, -0.0995,\n",
      "         0.0399, -0.0646,  0.0327, -0.0611, -0.0682, -0.0279,  0.0914,  0.0490,\n",
      "         0.0223,  0.0340, -0.0281,  0.0859,  0.0615,  0.0254,  0.0914, -0.0154,\n",
      "         0.0683, -0.0863, -0.0990,  0.0293, -0.0154, -0.0408, -0.0979,  0.0756,\n",
      "         0.0178, -0.0813, -0.0605,  0.0772, -0.0612, -0.0777, -0.0153,  0.0167],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0344, -0.0568,  0.0191,  ..., -0.0172, -0.0519, -0.0232],\n",
      "        [-0.0025, -0.0045, -0.0665,  ...,  0.0403,  0.0196,  0.0085],\n",
      "        [-0.0413, -0.0432, -0.0258,  ...,  0.0277,  0.0413, -0.0600],\n",
      "        ...,\n",
      "        [-0.0207, -0.0291,  0.0292,  ...,  0.0509,  0.0574,  0.0464],\n",
      "        [ 0.0559, -0.0349,  0.0414,  ...,  0.0564, -0.0282, -0.0217],\n",
      "        [ 0.0581, -0.0572, -0.0560,  ...,  0.0057, -0.0076, -0.0405]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0048,  0.0366,  0.0425, -0.0459, -0.0103,  0.0185, -0.0628, -0.0147,\n",
      "         0.0330,  0.0069], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0344, -0.0568,  0.0191,  ..., -0.0172, -0.0519, -0.0232],\n",
      "        [-0.0025, -0.0045, -0.0665,  ...,  0.0403,  0.0196,  0.0085],\n",
      "        [-0.0413, -0.0432, -0.0258,  ...,  0.0277,  0.0413, -0.0600],\n",
      "        ...,\n",
      "        [-0.0207, -0.0291,  0.0292,  ...,  0.0509,  0.0574,  0.0464],\n",
      "        [ 0.0559, -0.0349,  0.0414,  ...,  0.0564, -0.0282, -0.0217],\n",
      "        [ 0.0581, -0.0572, -0.0560,  ...,  0.0057, -0.0076, -0.0405]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0048,  0.0366,  0.0425, -0.0459, -0.0103,  0.0185, -0.0628, -0.0147,\n",
      "         0.0330,  0.0069], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.2020, 0.3365, 0.3266]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[-0.3348, -0.5433, -0.0779],\n",
      "        [ 0.1516,  0.1638, -0.4069]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0434, 0.0787], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[-0.2325,  0.0315]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6946, 0.1196, 0.3626, 0.6222, 0.9829, 0.5389],\n",
      "         [0.8939, 0.2264, 0.8566, 0.4545, 0.2193, 0.0213],\n",
      "         [0.0516, 0.3496, 0.7357, 0.8895, 0.9897, 0.3665],\n",
      "         [0.1950, 0.3224, 0.5995, 0.6878, 0.0798, 0.3647],\n",
      "         [0.4038, 0.8647, 0.7197, 0.3148, 0.8213, 0.8793],\n",
      "         [0.9650, 0.9923, 0.7416, 0.2851, 0.2516, 0.1265]]])\n",
      "tensor([[[0.8939, 0.9897],\n",
      "         [0.9923, 0.8793]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10.5452,  7.5498, 22.8696,  8.0273],\n",
      "         [10.4458, 23.7176,  8.3547, 21.2664],\n",
      "         [11.4952, 22.5223, 19.6715, 21.1600],\n",
      "         [16.4992, 21.5518, 17.6668,  9.0798]]])\n",
      "tensor(15.7764)\n",
      "tensor([[[-0.2730, -0.7533,  1.7030, -0.6767],\n",
      "         [-0.8278,  1.1697, -1.1426,  0.8007],\n",
      "         [-1.6835,  0.8887,  0.2238,  0.5710],\n",
      "         [ 0.0664,  1.1852,  0.3249, -1.5765]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(8.1956e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0250, 0.4277, 0.0000, 0.0000],\n",
      "         [0.0000, 0.2480, 0.0000, 0.0000],\n",
      "         [0.0000, 0.8171, 1.2974, 0.4660]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0556, 1.2485],\n",
      "         [0.0250, 0.0000, 0.0000, 0.0000],\n",
      "         [0.9682, 0.2480, 1.0967, 1.1592],\n",
      "         [0.2351, 0.8171, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
